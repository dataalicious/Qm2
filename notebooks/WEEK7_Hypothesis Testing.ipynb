{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "## *Workshop 7*  [![Open In Colab](https://github.com/oballinger/QM2/blob/main/colab-badge.png?raw=1)](https://colab.research.google.com/github/oballinger/QM2/blob/main/notebooks/W07.%20Hypothesis%20Testing.ipynb)\n",
    "\n",
    "For the rest of this course, we'll be working with data from the U.S. Census [Current Population Survey (CPS)](https://www.census.gov/programs-surveys/cps.html). \n",
    "\n",
    "### Aims:\n",
    "\n",
    "- Understanding:\n",
    "    - Confidence Intervals\n",
    "    - Hypothesis Testing\n",
    "        1. Stating the Null and Alternative Hypotheses\n",
    "        2. Selecting a Critical Value\n",
    "        3. Calculating the Test Statistic\n",
    "        4. Making a Decision\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "We will be following on from the analysis we conducted in Workshop 5 (Distributions and Basic Statistics). We visually explored differences in the income levels between different groups of people in the US census. Now, we are going to conduct hypothesis testing to see if those differences are statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/wk7\n",
    "!curl https://storage.googleapis.com/qm2/wk7/cps.csv -o data/wk7/cps.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This tells python to draw the graphs \"inline\" - in the notebook\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# make the plots (graphs) a little wider by default\n",
    "pylab.rcParams['figure.figsize'] = (10., 8.)\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/wk7/cps.csv')\n",
    "df['race']=df['race'].astype('category')\n",
    "df['income']=df['incwage']/1000\n",
    "df=df[df['income']<200]\n",
    "df=df[df['year']==2013] # filter the dataframe to only contain 2013 data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9YTGTBCRUqh"
   },
   "source": [
    "This is once again the U.S. census data from Week 5. As a reminder, our dataframe has 10 columns:\n",
    "\n",
    "1. *year*: Survey year\n",
    "2. *age*: the person's age\n",
    "3. *sex*: the person's sex \n",
    "    * 1=male\n",
    "    * 2=female\n",
    "4. *race*: the person's race \n",
    "    * White non hispanic=1\n",
    "    * Black non hispanic=2\n",
    "    * Hispanic=3\n",
    "    * Other non hispanic=4)\n",
    "5. *sch*: Educational attainment\n",
    "    * None = 0, \n",
    "    * Grades 1-12 = 1-12\n",
    "    * Some University = 13, \n",
    "    * Associate's degree = 14, \n",
    "    * BA = 16\n",
    "    * Advanced Degree = 18\n",
    "6. *union*: Union membership \n",
    "    * N/A = 0, \n",
    "    * No union coverage = 1, \n",
    "    * Member of labor union=2, \n",
    "    * Covered by union but not a member=3\n",
    "7. *incwage*: Wage and salary income\n",
    "8. *realhrwage*: Real Hourly Wage\n",
    "9. *occupation*: Occupation\n",
    "10. *ind*: [industry code](https://www.census.gov/naics/?58967?yearbck=2002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals \n",
    "\n",
    "So far in this workshop, we've had the luxury of being able to draw many random samples and plot the distributions of their sample means to infer the population mean. The Central Limit Theorem lets us assume that these sample means are normally distributed, and consequently that there is a 95.45% chance that the **population mean** within two standard errors of the **sample mean**. This allows us to make inferences on the basis of *a single sample*. The standard error is the \n",
    "\n",
    "### Sample Standard Deviation\n",
    "$$\\huge s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\overline{x})^2}$$\n",
    "\n",
    "### Standard Error\n",
    "$$\\huge se = \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "Given a large enough sample $x$, we can build a 95% confidence interval as follows:\n",
    "\n",
    "$$ \\huge 95\\% CI = \\overline{x} \\pm (1.96 \\times se)$$\n",
    "\n",
    "Let's draw a sample of 1000 random individuals from our data, and compute a 95% confidence interval to estimate the population mean for income. We'll begin by creating a swarmplot to get a sense of how the data are distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=df.sample(1000) # draw a random sample of 1000 observations from the dataframe\n",
    "sns.swarmplot(data = sample, y='income') # plot a swarmplot of income\n",
    "plt.title('Income Distribution') # add a title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set about calculating the 95% confidence interval and plotting it on our swarmplot. Luckily, the components we need to this are easy to calculate. We just need the mean, standard deviation, and number of observations. All of these are provided by the `.describe()` function, which calculates summary statistics for a sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=sample['income'].describe() # calculate descriptive statistics for the sample\n",
    "print(desc) # print the descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the set of descriptive statistics, we can pull out the relevant components, calculate the standard error, and create a 95% confidence interval as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=desc['mean'] # set the mean equal to a variable called \"mean\"\n",
    "std=desc['std'] # set the standard deviation equal to a variable called \"std\"\n",
    "n=desc['count'] # set the sample size equal to a variable called \"n\"\n",
    "se=std/np.sqrt(n) # calculate the standard error of the mean\n",
    "\n",
    "print('The mean is', round(mean, 2), 'with a standard error of', round(se, 2)) # print the mean and standard error\n",
    "\n",
    "upper_ci = mean+se*1.96 # calculate the upper confidence interval\n",
    "lower_ci = mean-se*1.96 # calculate the lower confidence interval\n",
    "\n",
    "print('The 95% confidence interval is', round(lower_ci, 2), 'to', round(upper_ci, 2)) # print the confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot these bounds on our swarmplot to graphically show this range. We can now claim that based on our sample, there is a 95% chance that the true population mean of income (shown in red) lies within this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data = sample, y='income',alpha=0.5) # plot a swarmplot of income\n",
    "plt.axhline(df['income'].mean(), color='red', linestyle='solid', linewidth=3, label='Population Mean') # add a horizontal line at the mean\n",
    "plt.axhline(upper_ci, color='black', linestyle='dashed', linewidth=3) # add a dashed black line at the upper confidence interval\n",
    "plt.axhline(lower_ci, color='black', linestyle='dashed', linewidth=3) # add a dashed black line at the lower confidence interval\n",
    "\n",
    "plt.title('Income Distribution, 95% Confidence Interval') # add a title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "If we create a boxplot of income disaggregated by sex using our sample, we can observe that men seem to earn more than women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=sample , x='sex', y='income').set_xticklabels(['Men','Women']) # make a box plot of income by sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But is this difference statistically significant? It could just be due to sampling error, random chance. **Hypothesis testing** provides a framework through which we can formally evaluate the likelihood of encountering an effect as extreme (in this case, the the difference between the mean incomes between both groups) as the one we observe in our data. There are four main steps in hypothesis testing: \n",
    "\n",
    "1. State the hypotheses. H0 states that there is no difference between the two population means.\n",
    "2. Select an $\\alpha$ level (e.g. 95% confidence), and select a corresponding **critical value** (1.96 for large samples)\n",
    "3. Compute the test statistic. \n",
    "4. Make a decision; if the test statistic exceeds the critical value, we **reject the null hypothesis**. \n",
    "\n",
    "Steps 1, 2, and 4 remain fairly constant regardless of what kind of hypothesis testing you're conducting. Step 3 can vary quite a bit, as there are many different statistical tests that fall under the umbrella of hypothesis testing. In today's workshop we'll be using the Student's T-Test (more on that in a second). For now, let's begin the process of hypothesis testing a\n",
    "\n",
    "### 1. State the hypotheses\n",
    "\n",
    "#### The Null Hypothesis\n",
    "* $H_0$ : There is no difference in the mean income between men and women\n",
    "* $H_0$ : $\\overline{x}_{men} = \\overline{x}_{women}$\n",
    "\n",
    "#### The Alternative Hypothesis\n",
    "* $H_a$ : There is a difference in the mean income between men and women\n",
    "* $H_a$ : $\\overline{x}_{men} \\neq \\overline{x}_{women}$\n",
    "\n",
    "### 2. Select an $\\alpha$ level\n",
    "\n",
    "Locate the critical region; the critical values for the t statistic are obtained using degrees of freedom ($df=n-2$). Given that we have 1000 observations, $df=998$. If $df>1000$, you can simply memorize the following critical values:\n",
    "\n",
    "* At the 95% confidence level, the critical value is 1.96\n",
    "* At the 99% confidence level, the critical value is 2.58\n",
    "\n",
    "If our test statistic exceeds either of these values, we can reject the null hypothesis with the according level of confidence. The function below creates a plot which provides a visual reference for these values, but isn't really necessary for the process of hypothesis testing. The function accepts one argument `test_statistic`, which it will use to plot a vertical red line. If the red line falls within the dotted lines, we fail to reject the null hypothesis at the corresponding confidence level. If it's outside of these bounds, we reject the null hypothesis. \n",
    "\n",
    "In the last line of code below, i've called the function to plot a test statistic of -2.3; Would we reject the null hypothesis at the 95% confidence level? what about the 99% level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_z(test_statistic):\n",
    "    mu, se= 0, 1 # create two variables, a mean \"mu\" equal to zero, and standard deviation \"se\" equal to 1\n",
    "    x = np.linspace(mu - 3*se, mu + 3*se, 100) # create a range of values from -3 to 3 standard deviations\n",
    "\n",
    "    plt.plot(x, norm.pdf(x, mu, se)) # plot the normal distribution\n",
    "    plt.axvline(mu-se*1.96, color='blue', linestyle='dashed', linewidth=1.5,label='µ ± 1.96σ (95% confidence)') # plot a vertical line at the mean plus 2 standard deviations\n",
    "    plt.axvline(mu+se*1.96, color='blue', linestyle='dashed', linewidth=1.5)  # plot a vertical line at the mean minus 2 standard deviations\n",
    "    plt.axvline(mu-se*2.58, color='green', linestyle='dashed', linewidth=1.5,label='µ ± 2.58σ (99% confidence)') # plot a vertical line at the mean plus 2 standard deviations\n",
    "    plt.axvline(mu+se*2.58, color='green', linestyle='dashed', linewidth=1.5)  # plot a vertical line at the mean minus 2 standard deviations\n",
    "    \n",
    "    plt.axvline(test_statistic, color='red', linestyle='solid', linewidth=1.5,label='Test Statistic') # plot a vertical line at the test statistic\n",
    "\n",
    "\n",
    "    plt.ylim(0,0.4)\n",
    "    plt.legend()\n",
    "    plt.title('Z Distribution') # add a title\n",
    "    plt.show()\n",
    "\n",
    "plot_z(-2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the Test Statistic (The Student's T-Test)\n",
    "\n",
    "The Student's T-Test is an *independent-measures design* which is used in situations where a researcher has no prior knowledge about either of the two populations (or treatments) being compared.  In particular, the population means and standard deviations are all unknown. Because the population variances are not known, these values must be estimated from the sample data. \n",
    "\n",
    "The purpose of a T-test is to determine whether the sample mean difference indicates a real mean difference between the two populations or whether the obtained difference is simply the result of sampling error. Given two groups, $x_1$ and $x_2$, the $t$ statistic is calculated as: \n",
    "\n",
    "$$ \\Huge t = {\\frac{\\overline{x_1}-\\overline{x_2}} {\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}}} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\overline{x}$: Sample Mean\n",
    "* $s^2$: Sample Standard Deviation\n",
    "* $n$: Number of observations\n",
    "\n",
    "We've already seen how to calculate each of these components when we made the 95% confidence interval above using the `.describe()` function. To calculate the t-statistic, we just have to plug these values into the formula above and do some basic arithmetic. I've put together a function that does this below, which accepts two main arguments, `group1` and `group2`. For each group it calculates descriptive statistics, and uses these values to calculate the t-statistic. It also has an optional argument `plot`, which when set to `True` will plot a 95% confidence interval for each group. It defaults to `False`, meaning that it won't generate the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_ttest(group1, group2, plot=False): # define a function called \"manual_ttest\" that takes two groups and a boolean value for whether or not to plot the results as arguments\n",
    "    \n",
    "    desc1, desc2=group1.describe(), group2.describe() # get descriptive statistics for both samples\n",
    "    \n",
    "    n1,std1,mean1 = desc1['count'], desc1['std'] ,desc1['mean'] # get the sample size, standard deviation, and mean of the first sample\n",
    "    n2,std2,mean2 = desc2['count'], desc2['std'] ,desc2['mean'] # get the sample size, standard deviation, and mean of the second sample\n",
    "    \n",
    "    # calculate standard errors\n",
    "    se1, se2 = std1**2/n1, std2**2/n2 # '**2' is the same as squaring the number\n",
    "\n",
    "    # standard error on the difference between the samples\n",
    "    sed = np.sqrt(se1 + se2)\n",
    "\n",
    "    # calculate the t statistic\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "\n",
    "    # print the results\n",
    "    print(\"Group 1: n=%.0f, mean=%.3f, std=%.3f\" % (n1,mean1,std1)) \n",
    "    print(\"Group 2: n=%.0f, mean=%.3f, std=%.3f\" % (n2,mean2,std2))\n",
    "    print('The t-statistic is %.3f' % t_stat) # print the t-statistic\n",
    "\n",
    "    if plot==True: # if the plot argument is set to True, plot the results\n",
    "        groups=pd.DataFrame() # create an empty dataframe\n",
    "        i=1 # create a counter variable called \"i\" and set it equal to 1\n",
    "        \n",
    "        for group in [group1, group2]: # loop through each group in the list of groups\n",
    "            plot_df=pd.DataFrame({'Values': group,'Group':i}) # create a dataframe with the values of the group and a column called \"Group\" that contains the group number\n",
    "            groups=groups._append(plot_df) # append the dataframe to the list of dataframes\n",
    "            i+=1 # increase the counter by 1\n",
    "        \n",
    "        sns.pointplot(data=groups , x='Group', y='Values',errorbar=('ci', 95), color='black', join=False, capsize=.8) # plot the means of the groups with a 95% confidence interval\n",
    "        plt.title('Comparison of Group Means with 95% Confidence Intervals') # add a title\n",
    "    \n",
    "    return t_stat # return the t-statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the function, we can now call it to calculate a t-test for the difference in income between men and women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men=sample[sample['sex']==1] # filter the sample to only include men\n",
    "women=sample[sample['sex']==2] # filter the sample to only include women\n",
    "\n",
    "t = manual_ttest(men['income'],women['income']) # run the t-test function and store the t-statistic in a variable called \"t\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make a Decision \n",
    "\n",
    "If the t statistic indicates that the obtained difference between sample means (numerator) is substantially greater than the difference expected by chance (denominator), we reject H0 and conclude that there is a real mean difference between the two populations or treatments. Let plot the T-statistic from our test against the critical values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_z(t) # plot the test statistic on the z distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above, can we reject the null hypothesis that there is no difference in mean income between men and women?\n",
    "\n",
    "### Exercise\n",
    "\n",
    "1. From the main dataframe `df`, draw a sample of 500 white men. Using t-tests, investigate whether there are statistically significant discrepancies in pay between white men and other groups (note: it would be best to sample 500 people in each of those groups as well). Between what groups does there exist the most significant pay gap?\n",
    "2. Some of this variation may be due to occupation. Compare income disparities between men and women within different occupations. Which occupation has the largest pay gap? which has the smallest? \n",
    "3. [Research suggests](https://journals.sagepub.com/doi/abs/10.1177/0730888401028004005) that within occupational groups, collective bargaining through union membership reduces pay gaps. Read the abstract of this article, and try to replicate the analysis using our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_men[['year','age','race','sex','union','sch','incwage','income']] = white_men[['year','age','race','sex','union','sch','incwage','income']].astype(float)\n",
    "hispanic_women[['year','age','race','sex','union','sch','incwage','income']] = hispanic_women[['year','age','race','sex','union','sch','incwage','income']].astype(float)\n",
    "black_men[['year','age','race','sex','union','sch','incwage','income']] = black_men[['year','age','race','sex','union','sch','incwage','income']].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_men = df[(df['race'] == int(1)) & (df['sex'] == int(1))].sample(n=int(500),random_state=int(1))\n",
    "hispanic_women = df[(df['race'] == int(3)) & (df['sex'] == int(2))].sample(n=int(500),random_state=int(1))\n",
    "black_men = df[(df['race'] == int(2)) & (df['sex'] == int(2))].sample(n=int(500),random_state=int(1))\n",
    "t1 = manual_ttest(white_men['income'], hispanic_women['income'])\n",
    "plot_z(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = manual_ttest(white_men['income'], black_men['income'])\n",
    "plot_z(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessed Question\n",
    "\n",
    "When Elon musk bought Twitter, he promisted to restore \"free speech\" to the platform. He heralded this new era with a tweet on 28/10/2022, which read \"the bird is freed\". A tidal wave of hate speech ensued instead. \n",
    "\n",
    "Using twitter's API, I downloaded tweets containing a racial slur. Using the groupby function and regex, I counted the number of mentions of this word per hour on the platform for about a month before the takeover, and a few days thereafter. I've saved these counts (but not the tweets themselves) as a csv file called \"elon_tweets.csv\".\n",
    "\n",
    "The code below downloads this csv file, and plots the number of slur-containing tweets over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://storage.googleapis.com/qm2/wk7/elon_twitter.csv -o data/wk7/elon_twitter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "tweets=pd.read_csv('data/wk7/elon_twitter.csv') # read in the data\n",
    "figure(figsize=(10, 4), dpi=200)\n",
    "tweets['hour']=pd.to_datetime(tweets['hour'])\n",
    "\n",
    "tweet=datetime.datetime(2022, 10, 28)\n",
    "\n",
    "pre_mean=tweets[tweets['hour']<tweet]['count'].mean()\n",
    "post_mean=tweets[tweets['hour']>tweet]['count'].mean()\n",
    "pct_change= int(((post_mean-pre_mean)/pre_mean)*100)\n",
    "\n",
    "plt.ylabel('Hourly Slur Tweets')\n",
    "\n",
    "plt.plot_date(tweets['hour'], tweets['count'], 'b', color='red')\n",
    "plt.axvline(tweet, color='black', linestyle='dashed', label='\"the bird is freed\"')\n",
    "plt.legend()\n",
    "plt.title('Elon Musk tweets \"The bird is freed\"; Tweets containing racial slurs increase {}%'.format(pct_change))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot definitely shows an uptick in the number of tweets containing a racial slur following Musk's tweet. But is this increase statistically significant? Using a t-test and the full hypothesis testing procedure, investigate wheter there was a statistically significant increase in hate speech following Elon Musk's tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_bird = tweets[tweets['hour'] <= tweet].sample(100) \n",
    "post_bird = tweets[tweets['hour'] > tweet]\n",
    "t = manual_ttest(post_bird['count'], pre_bird['count'], True)\n",
    "plot_z(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a statistically siginficance in the tweet and increase of racial slurs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.1",
   "language": "sage",
   "name": "SageMath-10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d80b9f83908a8d8a87f66ec6dbbbc64a677a1cd701fced73fa9bc54e3d46eecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
